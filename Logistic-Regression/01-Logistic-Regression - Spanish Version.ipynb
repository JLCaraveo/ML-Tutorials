{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ace67d3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc42578",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La regresión Logística es un tipo de análisis de regresión utilizado para predecir el resultado de una variable categórica, es decir, utilizado para clasificar un conjunto de datos de acuerdo a las posibles categorías dadas por la variable a predecir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aad4232",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Hipótesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe033b52",
   "metadata": {
    "hidden": true
   },
   "source": [
    "El algoritmo predice la probabilidad de que, cierto ejemplo, pertenezca a una determinada categoría. Pero, para cada caso de estudio se tendrá que especificar un umbral de aprobación, es un número del 0 al 1, dado por el usuario, el cual va a determinar que, si la probabilidad es mayor a este umbral entonces este ejemplo pertenece a cierta categoría.\n",
    "\n",
    "Teniendo esto claro, nuestra hipótesis queda de la siguiente manera:\n",
    "\n",
    "Vamos a usar un umbral de 0.5, por lo tanto:\n",
    "\n",
    "* Si $h_0(x) \\ge 0.5$, la predicción será \"$y=1$\"\n",
    "* Si $h_0(x) \\le 0.5$, la predicción será \"$y=0$\"\n",
    "\n",
    "Se debe tener en cuenta que $0 \\le h_0 \\le 1$.\n",
    "\n",
    "Y como se obtiene $h_0$:\n",
    "\n",
    "$$h_0(x) = g(\\theta_0 + \\theta_1 \\cdot x_1 +  \\theta_2 \\cdot x_2 + \\dots +  \\theta_n \\cdot x_n) = g(z)$$\n",
    "\n",
    "donde:\n",
    "\n",
    "* $g(z) = \\frac{1}{1 + e^{-\\theta^T \\cdot X}}$\n",
    "\n",
    "Nos detenemos a analizar las fórmulas. Primero, se obtiene el valor de $\\theta^T \\cdot X$ y a este resultado se aplica una función la cual nos pueda convertir el resultado de $\\theta^T \\cdot X$ a uno que vaya entre el rango de 0 a 1, y así, dado el umbral podamos decidir si ese ejemplo lo podamos catalogar como \"$y=1$\" o \"$y=0$\".\n",
    "\n",
    "Esta función es la llamada función sigmoide:\n",
    "\n",
    "$$Sigmoide = \\frac{1}{1 + e^{-X}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbc6ffa",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Función de coste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8ffd08",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La función de coste para una regresión lineal es la siguiente:\n",
    "\n",
    "$$J(\\theta_0,\\ \\theta_1) = \\frac{1}{2m} \\sum_{i=1}^{m}(h_0(x^i) - y^i)^2$$\n",
    "\n",
    "Para la regresión logística no podemos utilizar esta misma, ya que esto nos dará como resultado una función no convexa, por lo que nunca se lograría encontrar un mínimo global óptimo para minimizar esta misma.\n",
    "\n",
    "Tenemos que modificar esta función para tomar en cuenta los dos posibles resultados \"$y=1$\" y \"$y=0$\". Nuestra función de costo quedaría de la siguiente manera:\n",
    "\n",
    "$$\n",
    "Cost(h_0(x), y) = \\left \\{\n",
    "\\begin{array}{ll}\n",
    "-log(h_0(x)) & if\\ y=1 \\\\\n",
    "-log(1 - h_0(x)) & if\\ y=0\n",
    "\\end{array}\n",
    "\\right .\n",
    "$$\n",
    "\n",
    "Pero lo anterior pueda que sea difícil de comprender, para ello simplificamos la función para que nos quede de la siguiente manera:\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m Cost(h_0(x_i), y_i)$$\n",
    "\n",
    "Tomando como referencia las ecuaciones para \"$y=1$\" y \"$y=0$\", tenemos una fórmula que engloba los dos posibles resultados:\n",
    "\n",
    "$$J(\\theta) = - \\frac{1}{m} \\left [ \\sum_{i=1}^m y_i log(h_0(x_i)) + (1-y_i)log(1 - h_0(x_i)) \\right]$$\n",
    "\n",
    "Para hacer la predicción de un nuevo elemento $x$:\n",
    "\n",
    "$$Output\\ h_0(x) = \\frac{1}{1+e^{-\\theta^T x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4093472",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Descenso del gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98131b9c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Como obtenemos los $\\theta$ óptimos?\n",
    "\n",
    "Como en el algoritmo de regresión lineal, usaremos el descenso del gradiente para ayudarnos a encontrar estos parámetros. El algoritmo es el siguiente:\n",
    "\n",
    "Repetir hasta converger {\n",
    "    $$\\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m}(h_0(x^i) - y^i)\\cdot x^i_j$$\n",
    "\n",
    "}\n",
    "\n",
    "donde:\n",
    "* $\\alpha$ es la tasa de aprendizaje.\n",
    "\n",
    "Notamos que el algoritmo luce idéntico al de regresión lineal, pero hay que dejar algo claro, ahora, la función para calcular $h_0(x)$ es distinta, se tiene que usar:\n",
    "\n",
    "$$h_0(x) = \\frac{1}{1+e^{-\\theta^T x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f11b11",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Implementación en código"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357da5f4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Un dataset de ejemplo que nos ayuda a entender como el algoritmo de regresión logística es usado es el dataset de predicción de tumores Malignos o Benignos con base a ciertas características.\n",
    "\n",
    "El dataset que se utilizará nos proporciona características de los tumores como \n",
    "\n",
    "* identificación\n",
    "* diagnóstico\n",
    "* radio_promedio\n",
    "* textura_media\n",
    "* perímetro_medio\n",
    "* área_media\n",
    "* suavidad_media\n",
    "* compacidad_media\n",
    "media_concavidad\n",
    "* puntos cóncavos_media\n",
    "* simetría_media\n",
    "\n",
    "Entre otros datos importantes. Para esto, intentaremos predecir el diagnóstico (M = Maligno, B = Benigno) según las especificaciones de cada tumor.\n",
    "\n",
    "Los datos se encuentran en el siguiente link: https://www.kaggle.com/yasserh/breast-cancer-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be4a7e67",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5070a4bf",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/breast-cancer.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261e9a74",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Contamos con 569 ejemplos y 30 características, no tomamos en cuenta el ID, ni el diagnóstico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "379dbd05",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212, 357)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['diagnosis'][data['diagnosis'] == 'M'].count(), \\\n",
    "data['diagnosis'][data['diagnosis'] == 'B'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edaa539",
   "metadata": {
    "hidden": true
   },
   "source": [
    "El dataset se conforma de 212 casos de tumores Malignos y 357 casos de tumores Benignos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22af9d0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Cuando se va aplicar un algoritmo de regresión, es importante verificar que los datos con los que se va a trabajar sean numéricos. De lo contrario, se tendrá que realizar un trabajo de transformación que nos ayude a convertir las variables categóricas a numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79b8aae6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d685d8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Todos nuestros datos son numéricos, por lo que no es necesaria una transformación antes de aplicar el algoritmo, tampoco tenemos datos nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c83799a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Variables que se usarán para el algoritmo\n",
    "X = data.iloc[:, 2:]\n",
    "m = len(X)\n",
    "y = data['diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b873db",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La variable a predecir es categórica, por lo que se tiene que transformar a numérica. Normalmente se utiliza una técnica de encoding, pero en este caso de estudio tenemos dos posibles resultados, por lo tanto:\n",
    "\n",
    "* $y=1$ cuando el diagnóstico sea \"M\".\n",
    "* $y=0$ cuando el diagnóstico sea \"B\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4f44bd7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = y.apply(lambda x: 0 if x == 'B' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b37fc7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Para poder manejar una solución vectorizada, es necesario agregar una columna de unos al inicio de las variables X, esto nos ayuda a que $\\theta_0$ no sea modificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e24725ae",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ones = [1] * len(X)\n",
    "\n",
    "X.insert(0, 'ones', ones)\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdc25c86",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "329ccb8c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Función Sigmoide\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.e**(-x))\n",
    "\n",
    "# Función de predicción\n",
    "def get_y_pred(x, thetas):\n",
    "    return sigmoid(x.dot(thetas.T))\n",
    "\n",
    "# Función de coste\n",
    "def get_cost(y, y_pred):\n",
    "    cost = 0\n",
    "    for i in range(m):\n",
    "        cost += (y[i] * np.log(y_pred[i])) + ((1-y[i]) * np.log(1-y_pred[i]))\n",
    "    return -1 * (1/m) * cost\n",
    "\n",
    "# Gradiente Descendente\n",
    "def get_gradient(x, y, n_iter, thetas, alpha=0.01):\n",
    "    for i in range(n_iter):\n",
    "        y_pred = get_y_pred(x, thetas)\n",
    "        \n",
    "        thetas = thetas - (alpha * ((1 / m)*((y_pred - y).T.dot(x))))\n",
    "        \n",
    "    return thetas\n",
    "\n",
    "\n",
    "# Obteniendo los theta óptimos\n",
    "initial_thetas = np.zeros([X.shape[1]]).T\n",
    "n_iter = 100000\n",
    "thetas = get_gradient(X, y, n_iter, initial_thetas)\n",
    "\n",
    "# Obteniendo las predicciones de acuerdo a los theta óptimos.\n",
    "y_pred = get_y_pred(X, thetas)\n",
    "\n",
    "# Obtener 0 o 1 de acuerdo al threshold.\n",
    "threshold = 0.5\n",
    "y_pred2 = [1 if pred > threshold else 0 for pred in y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be56bca",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La mejor manera de verificar que tan bien está prediciendo nuestro modelo es usar una matriz de confusión, esta nos ayuda a verificar, verdaderos positivos, verdaderos negativos, falsos positivos y falsos negativos.\n",
    "\n",
    "La librería de Sklearn nos proporciona una función para obtener esta matriz. La cual da como resultado una matriz como sigue:\n",
    "\n",
    "$$\\begin{pmatrix} Verdaderos\\ Positivos & Falsos\\ Positivos \\\\ Falsos\\ Negativos & Verdaderos\\ Negativos \\end{pmatrix}$$\n",
    "\n",
    "Esta matriz también nos ayuda a calcular:\n",
    "\n",
    "* Accuracy: De las predicciones, cual es la proporción que el algoritmo predice correctamente.\n",
    "\n",
    "$$Accuracy = \\frac{Verdaderos\\ Positivos\\ +\\ Verdaderos\\ Negativos}{m}$$\n",
    "\n",
    "* Precisión: Del total de predicciones positivas, que proporción realmente es verdadero positivo.\n",
    "\n",
    "$$Precisión = \\frac{Verdaderos\\ Positivos}{Verdaderos\\ Positivos\\ +\\ Falsos\\ Positivos}$$\n",
    "\n",
    "* Recall: Del total de predicciones positivas, que proporción realmente predice como verdadero positivo.\n",
    "\n",
    "$$Recall = \\frac{Verdaderos\\ Positivos}{Verdaderos\\ Positivos\\ +\\ Falsos\\ Negativos}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1e470d2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9121265377855887, Precisión: 0.9971988795518207, Recall: 0.8790123456790123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y, y_pred2)\n",
    "\n",
    "VP = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1]\n",
    "VN = conf_matrix[1][1]\n",
    "FN = conf_matrix[1][0]\n",
    "\n",
    "accuracy = (VP + VN) / m\n",
    "presicion = VP / (VP + FP)\n",
    "recall = VP / (VP + FN)\n",
    "\n",
    "print('Accuracy: {}, Precisión: {}, Recall: {}'.format(accuracy, presicion, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0353bc59",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nuestro algoritmo obtiene una precisión del casi 100%, con una precisión y recall altos. Por lo que se concluye que este algoritmo ayuda a predecir casi con 100% de exactitud un tumor Maligno o Benigno."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c6c2a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Algoritmo con Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d66ffc4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9121265377855887, Precisión: 0.9971988795518207, Recall: 0.8790123456790123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = data.iloc[:, 2:].values\n",
    "m = len(X)\n",
    "y = data['diagnosis']\n",
    "\n",
    "# Convirtiendo los datos categóricos a numéricos\n",
    "y = y.apply(lambda x: 0 if x == 'B' else 1)\n",
    "\n",
    "# Entrenando el modelo\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Obteniendo predicciones\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(y, y_pred2)\n",
    "\n",
    "VP = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1]\n",
    "VN = conf_matrix[1][1]\n",
    "FN = conf_matrix[1][0]\n",
    "\n",
    "accuracy = (VP + VN) / m\n",
    "presicion = VP / (VP + FP)\n",
    "recall = VP / (VP + FN)\n",
    "\n",
    "print('Accuracy: {}, Precisión: {}, Recall: {}'.format(accuracy, presicion, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d79611",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Podemos Observar como obtenemos los mismos resultados, pero con la ventaja de que ahora el procedimiento se aplica con pocas líneas de código."
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "José Luis Higuera Caraveo"
   }
  ],
  "colab": {
   "collapsed_sections": [
    "uW-Xfqevr7Sy"
   ],
   "name": "Recursos Humanos",
   "provenance": []
  },
  "date": "February 28 2022",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "title": "Regresión Logística con Python"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
